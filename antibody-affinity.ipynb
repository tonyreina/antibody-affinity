{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfa557f-bd90-44d8-bd85-fe540ce9ed85",
   "metadata": {},
   "source": [
    "# ESM2 Embedder using HuggingFace\n",
    "\n",
    "[ESM2 protein language model](https://github.com/facebookresearch/esm) to embed protein sequences into an embedding space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3769b1e8-0dfb-433b-b10d-e36d5c627181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b51bf5c-1167-4fe6-9a5c-761e091593a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed0326-6a36-4c09-9352-0d12f1a114b9",
   "metadata": {},
   "source": [
    "## Load HuggingFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7bc44b-3124-4471-b816-ebc177f93a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9747493-1dc3-4084-b165-0fb835192e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = EsmModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55372ba6-3c5f-436c-9452-a6d829461e69",
   "metadata": {},
   "source": [
    "Put tensor(s) on the best hardware device. If CUDA (GPU) is available, then use that. If not, then use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333a6ac4-30a6-4af6-a1de-5aaafa34970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799849ec-c50c-4e15-aed2-1654595a2763",
   "metadata": {},
   "source": [
    "## Multimers\n",
    "\n",
    "If the protein consists of multiple chains (multimers), then connect them as one long sequence string by inserting a chain of \"G\" in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745a4147-cbfe-47cc-9eb9-0e6b1c40e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_A = \"MRLIPLHNVDQVAKWSARYIVDRINQFQPTEARPFVLGLPTGGTPLKTYEALIELYKAGEVSFKHVVTFNMDEYVGLPKEHPESYHSFMYKNFFDHVDIQEKNINILNGNTEDHDAECQRYEEKIKSYGKIHLFMGGVGVDGHIAFNEPASSLSSRTRIKTLTEDTLIANSRFFDNDVNKVPKYALTIGVGTLLDAEEVMILVTGYNKAQALQAAVEGSINHLWTVTALQMHRRAIIVCDEPATQELKVKTVKYFTELEASAIRSVK\"\n",
    "chain_B = \"HPESYHSFMYKNFFDHVDIQEKRTTDINRT\"\n",
    "\n",
    "linker_sequence = \"G\" * 25  # Put G linker in between chains (remove it later)\n",
    "\n",
    "multimer_sequence = chain_A + linker_sequence + chain_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8cb2a6-f9dd-40b6-b096-3694fc283464",
   "metadata": {},
   "source": [
    "Tokenize the input sequence string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cbd1e57-fa4f-4575-8cfb-958f7d5ca5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_multimer = tokenizer([multimer_sequence], return_tensors=\"pt\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31bad9-3490-4667-a661-5dc794dec0bd",
   "metadata": {},
   "source": [
    "Renumber the positions of the second chain so that the model knows that the second chain is not really connected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c492d3-8867-45b1-ae16-9f454f600bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    position_ids = torch.arange(len(multimer_sequence), dtype=torch.long)\n",
    "    position_ids[len(chain_A) + len(linker_sequence):] += 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1798bdba-ad3c-4f5b-a4b7-e00b43a4c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_multimer['position_ids'] = position_ids.unsqueeze(0)\n",
    "\n",
    "tokenized_multimer = {key: tensor.to(device) for key, tensor in tokenized_multimer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7812743e-feef-4a00-90c5-9c5d0401e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(**tokenized_multimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42af4730-e246-40f2-a5e3-c8ec49ce7764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3f886-d1ad-4ca6-9155-72a2910a3431",
   "metadata": {},
   "source": [
    "The embeddings are the last hidden state of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b780eb8-3e25-4502-8312-1ce9bba39693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 322, 320])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"last_hidden_state\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa4adda-a594-4d57-ab78-9688d589cab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([322])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a64076-643f-4823-92a7-316b65764b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
