{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfa557f-bd90-44d8-bd85-fe540ce9ed85",
   "metadata": {},
   "source": [
    "# ESM2 Protein Folding using HuggingFace\n",
    "\n",
    "[ESMFold protein language model](https://github.com/facebookresearch/esm) to fold protein sequences based only on the protein sequence. \n",
    "\n",
    "This also demonstrates how to handle multimer predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769b1e8-0dfb-433b-b10d-e36d5c627181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51bf5c-1167-4fe6-9a5c-761e091593a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed0326-6a36-4c09-9352-0d12f1a114b9",
   "metadata": {},
   "source": [
    "## Load HuggingFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bc44b-3124-4471-b816-ebc177f93a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmForProteinFolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9747493-1dc3-4084-b165-0fb835192e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esmfold_v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = EsmForProteinFolding.from_pretrained(model_name, low_cpu_mem_usage=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55372ba6-3c5f-436c-9452-a6d829461e69",
   "metadata": {},
   "source": [
    "Put tensor(s) on the desired hardware device. If CUDA (GPU) is available, then use that. If not, then use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a6ac4-30a6-4af6-a1de-5aaafa34970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.esm = model.esm.half()\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    # Use chunks if your GPU memory is 16GB or less\n",
    "    model.trunk.set_chunk_size(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799849ec-c50c-4e15-aed2-1654595a2763",
   "metadata": {},
   "source": [
    "## Multimers\n",
    "\n",
    "If the protein consists of multiple chains (multimers), then connect them as one long sequence string by inserting a chain of \"G\" in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a4147-cbfe-47cc-9eb9-0e6b1c40e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_A = \"MRLIPLHNVDQVAKWSARYIVDRINQFQPTEARPFVLGLPTGGTPLKTYEALIELYKAGEVSFKHVVTFNMDEYVGLPKEHPESYHSFMYKNFFDHVDIQEKNINILNGNTEDHDAECQRYEEKIKSYGKIHLFMGGVGVDGHIAFNEPASSLSSRTRIKTLTEDTLIANSRFFDNDVNKVPKYALTIGVGTLLDAEEVMILVTGYNKAQALQAAVEGSINHLWTVTALQMHRRAIIVCDEPATQELKVKTVKYFTELEASAIRSVK\"\n",
    "chain_B = \"HPESYHSFMYKNFFDHVDIQEKRTTDINRTQVAKWSARYIVDRINQFQPTHVGIQEKRATDIN\"\n",
    "\n",
    "linker_sequence = \"G\" * 25  # Put G linker in between chains (hide it later)\n",
    "\n",
    "multimer_sequence = chain_A + linker_sequence + chain_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8cb2a6-f9dd-40b6-b096-3694fc283464",
   "metadata": {},
   "source": [
    "Tokenize the input sequence string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd1e57-fa4f-4575-8cfb-958f7d5ca5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_multimer = tokenizer([multimer_sequence], return_tensors=\"pt\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31bad9-3490-4667-a661-5dc794dec0bd",
   "metadata": {},
   "source": [
    "Renumber the positions of the second chain so that the model knows that the second chain is not really connected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c492d3-8867-45b1-ae16-9f454f600bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    position_ids = torch.arange(len(multimer_sequence), dtype=torch.long)\n",
    "    position_ids[len(chain_A) + len(linker_sequence):] += 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798bdba-ad3c-4f5b-a4b7-e00b43a4c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_multimer['position_ids'] = position_ids.unsqueeze(0)\n",
    "\n",
    "tokenized_multimer = {key: tensor.to(device) for key, tensor in tokenized_multimer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812743e-feef-4a00-90c5-9c5d0401e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(**tokenized_multimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af4730-e246-40f2-a5e3-c8ec49ce7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a6882-e624-44a6-8a3e-78aa56c813dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_mask = torch.tensor([1] * len(chain_A) + [0] * len(linker_sequence) + [1] * len(chain_B))[None, :, None]\n",
    "\n",
    "output['atom37_atom_exists'] = output['atom37_atom_exists'] * linker_mask.to(output['atom37_atom_exists'].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302a9a5-0a29-460c-a0ce-b27ca79d5445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca314987-e5d6-438d-812f-6740c0314948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92c198-b6c0-48bc-81c9-7a29ef7f48a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a64076-643f-4823-92a7-316b65764b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.esm.openfold_utils.protein import to_pdb, Protein as OFProtein\n",
    "from transformers.models.esm.openfold_utils.feats import atom14_to_atom37\n",
    "\n",
    "def convert_outputs_to_pdb(outputs):\n",
    "    final_atom_positions = atom14_to_atom37(outputs[\"positions\"][-1], outputs)\n",
    "    outputs = {k: v.to(\"cpu\").numpy() for k, v in outputs.items()}\n",
    "    final_atom_positions = final_atom_positions.cpu().numpy()\n",
    "    final_atom_mask = outputs[\"atom37_atom_exists\"]\n",
    "    pdbs = []\n",
    "    for i in range(outputs[\"aatype\"].shape[0]):\n",
    "        aa = outputs[\"aatype\"][i]\n",
    "        pred_pos = final_atom_positions[i]\n",
    "        mask = final_atom_mask[i]\n",
    "        resid = outputs[\"residue_index\"][i] + 1\n",
    "        pred = OFProtein(\n",
    "            aatype=aa,\n",
    "            atom_positions=pred_pos,\n",
    "            atom_mask=mask,\n",
    "            residue_index=resid,\n",
    "            b_factors=outputs[\"plddt\"][i],\n",
    "            chain_index=outputs[\"chain_index\"][i] if \"chain_index\" in outputs else None,\n",
    "        )\n",
    "        pdbs.append(to_pdb(pred))\n",
    "    return pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e383192-026e-4057-8b07-bb352cbdeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = convert_outputs_to_pdb(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea7de3-e7e7-4e7a-8cb8-9d0f5ccac753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py3Dmol\n",
    "\n",
    "view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js', width=800, height=400)\n",
    "view.addModel(\"\".join(pdb), 'pdb')\n",
    "view.setStyle({'model': -1}, {\"cartoon\": {'color': 'spectrum'}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
